{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a8b64d6f-a0f3-4b20-a76d-9265f4ceb568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114000, 21)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "data = pd.read_csv('KaggleDataset.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "59ed8466-13de-49a5-b4f1-48c36ddc4521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113999, 21)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "59b5071a-3595-4785-b335-fd7d322da433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Distribution: is_hit\n",
      "0    106006\n",
      "1      2293\n",
      "Name: count, dtype: int64\n",
      "Test Class Distribution: is_hit\n",
      "0    5579\n",
      "1     121\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define target\n",
    "data['is_hit'] = (data['popularity'] > 75).astype(int)\n",
    "\n",
    "# Drop unneccesary columns to speed up model training\n",
    "X = pd.get_dummies(data.drop(columns=['popularity', 'is_hit', 'track_id', 'album_name', 'track_name', 'track_genre', 'artists'], errors='ignore'))\n",
    "y = data['is_hit']\n",
    "\n",
    "# Training and testing sets (because dataset is large, I'll use 5% for test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=20, stratify=y)\n",
    "\n",
    "print(\"Training Class Distribution:\", y_train.value_counts())\n",
    "print(\"Test Class Distribution:\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e5380-eafd-4431-888c-2a03f34e7713",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5c4c8481-f267-4248-9872-0511556a88d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90      5579\n",
      "           1       0.09      0.87      0.17       121\n",
      "\n",
      "    accuracy                           0.82      5700\n",
      "   macro avg       0.55      0.84      0.53      5700\n",
      "weighted avg       0.98      0.82      0.88      5700\n",
      "\n",
      "AUC-ROC: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=21, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "#y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.03  # Adjust to a lower threshold\n",
    "y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba) # For finding optimal threshold\n",
    "# Evaluate the model\n",
    "classification_rep = classification_report(y_test, y_pred_thresholded)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_thresholded)\n",
    "\n",
    "# Display\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"AUC-ROC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdda72-e62e-4ced-a95f-c0ba88e2d84e",
   "metadata": {},
   "source": [
    "Recall: 87%\n",
    "Precision: 9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3c0035c7-5fe6-4343-ac6a-da16a0e23b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0 Recall: 1.0 Precision: 0.02\n",
      "Threshold: 0.01 Recall: 0.96 Precision: 0.04\n",
      "Threshold: 0.02 Recall: 0.9 Precision: 0.06\n",
      "Threshold: 0.03 Recall: 0.87 Precision: 0.09\n",
      "Threshold: 0.04 Recall: 0.83 Precision: 0.14\n",
      "Threshold: 0.05 Recall: 0.81 Precision: 0.2\n",
      "Threshold: 0.06 Recall: 0.77 Precision: 0.26\n",
      "Threshold: 0.07 Recall: 0.74 Precision: 0.32\n",
      "Threshold: 0.08 Recall: 0.72 Precision: 0.37\n",
      "Threshold: 0.09 Recall: 0.72 Precision: 0.47\n",
      "Threshold: 0.1 Recall: 0.71 Precision: 0.53\n",
      "Threshold: 0.11 Recall: 0.71 Precision: 0.58\n",
      "Threshold: 0.12 Recall: 0.71 Precision: 0.63\n",
      "Threshold: 0.13 Recall: 0.7 Precision: 0.69\n",
      "Threshold: 0.14 Recall: 0.69 Precision: 0.72\n",
      "Threshold: 0.15 Recall: 0.69 Precision: 0.74\n",
      "Threshold: 0.16 Recall: 0.68 Precision: 0.75\n",
      "Threshold: 0.17 Recall: 0.66 Precision: 0.76\n",
      "Threshold: 0.18 Recall: 0.65 Precision: 0.79\n",
      "Threshold: 0.19 Recall: 0.65 Precision: 0.81\n",
      "Threshold: 0.2 Recall: 0.65 Precision: 0.81\n",
      "Threshold: 0.21 Recall: 0.65 Precision: 0.82\n",
      "Threshold: 0.22 Recall: 0.64 Precision: 0.82\n",
      "Threshold: 0.23 Recall: 0.63 Precision: 0.83\n",
      "Threshold: 0.25 Recall: 0.63 Precision: 0.84\n",
      "Threshold: 0.26 Recall: 0.62 Precision: 0.84\n",
      "Threshold: 0.27 Recall: 0.61 Precision: 0.86\n",
      "Threshold: 0.28 Recall: 0.6 Precision: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Finding threshold suitable for my goal (recall >= 0.85)\n",
    "# If the goal to successfully predict song popularity score over 75 was lower than 85% of the time\n",
    "# then precision would have been drastically better\n",
    "for p, r, t in zip(precision, recall, thresholds):\n",
    "    if r >= 0.6:\n",
    "        print(\"Threshold:\", round(t, 2), \"Recall:\", round(r, 2), \"Precision:\", round(p, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354ce84-fdd0-4ae0-a8e7-6b353e559c3a",
   "metadata": {},
   "source": [
    "### Random Forest Model with balanced data and scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7c1fa7c3-3c60-49e3-bea1-2a7909309100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ba362550-0d7f-4fff-8b7e-a442753ada1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bce5e2bd-100a-4b18-ae03-30b7252f5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86      5579\n",
      "           1       0.07      0.86      0.13       121\n",
      "\n",
      "    accuracy                           0.75      5700\n",
      "   macro avg       0.53      0.80      0.49      5700\n",
      "weighted avg       0.98      0.75      0.84      5700\n",
      "\n",
      "AUC-ROC: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=21, n_estimators=100)\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "threshold = 0.1  # Adjust to a lower threshold\n",
    "y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "classification_rep = classification_report(y_test, y_pred_thresholded)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_thresholded)\n",
    "\n",
    "# Display metrics and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"AUC-ROC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56033f9-411b-40e7-bc2e-6b0582bc9508",
   "metadata": {},
   "source": [
    "Recall: 86%\n",
    "Precision: 7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d7596-8199-4bfa-a7c7-b7474e5bdb60",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb16ae8-4c12-41fa-9a9c-da580814cdae",
   "metadata": {},
   "source": [
    "Trying to balance out the dataset.\n",
    "Using class_weight to distribute weight between classes.\n",
    "\n",
    "**Formula of Class Weights:**\n",
    "wj=n_samples / (n_classes * n_samplesj)\n",
    "\n",
    "+ wj is the weight for each class(j signifies the class)\n",
    "+ n_samplesis the total number of samples or rows in the dataset\n",
    "+ n_classesis the total number of unique classes in the target\n",
    "+ n_samplesjis the total number of rows of the respective class\n",
    "\n",
    "Popularity under 75: 113 999 / 2 * 111 585 = 113 999 / 223 170 = 0.51\n",
    "\n",
    "Popularity under 75: 113 999 / 2 * 2414 = 113 999 / 4828 = 23.61\n",
    "\n",
    "Can't put weight for class 1 too high as the model will then heavily favor predicting class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dba7e855-8778-40e8-897e-5aa7801953bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ecbfb066-7f1a-4f1c-a72f-7d31e304024d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Linear SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75      5579\n",
      "           1       0.04      0.78      0.08       121\n",
      "\n",
      "    accuracy                           0.61      5700\n",
      "   macro avg       0.52      0.69      0.41      5700\n",
      "weighted avg       0.97      0.61      0.74      5700\n",
      "\n",
      "AUC-ROC: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and use LinearSVC\n",
    "svm_model = make_pipeline(StandardScaler(), LinearSVC(class_weight={0: 0.51, 1: 23.61}, random_state=42, max_iter=10000))\n",
    "\n",
    "# Fit the model on the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test) # Not useful to adjust threshold\n",
    "\n",
    "# Linear SVM does not provide probabilities directly, but we can use the decision function\n",
    "y_scores = svm_model.decision_function(X_test)\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "print(\"Classification Report (Linear SVM):\")\n",
    "print(classification_rep)\n",
    "print(\"AUC-ROC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f0d6f-7673-49bb-b898-c849d2cd47fe",
   "metadata": {},
   "source": [
    "Recall: 78%\n",
    "Precision: 4%\n",
    "\n",
    "### Linear SVM with balanced data and scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8935cacb-e57d-4148-8a19-9d0d0bb9c338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Linear SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83      5579\n",
      "           1       0.04      0.55      0.08       121\n",
      "\n",
      "    accuracy                           0.72      5700\n",
      "   macro avg       0.51      0.63      0.45      5700\n",
      "weighted avg       0.97      0.72      0.82      5700\n",
      "\n",
      "AUC-ROC: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and use LinearSVC\n",
    "svm_model = make_pipeline(StandardScaler(), LinearSVC(class_weight='balanced', random_state=42, max_iter=10000))\n",
    "\n",
    "# Fit the model on the training data\n",
    "svm_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Linear SVM does not provide probabilities directly, but we can use the decision function\n",
    "y_scores = svm_model.decision_function(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "print(\"Classification Report (Linear SVM):\")\n",
    "print(classification_rep)\n",
    "print(\"AUC-ROC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc69852-1dbc-4266-a292-f13d1cda2d95",
   "metadata": {},
   "source": [
    "Recall: 55%\n",
    "Precision: 4%\n",
    "\n",
    "### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e55833d5-0335-42d9-af1b-9e914b42a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dea1ddc1-704d-4c69-91c3-563963b3c3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (K-Nearest Neighbors):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86      5579\n",
      "           1       0.07      0.86      0.13       121\n",
      "\n",
      "    accuracy                           0.75      5700\n",
      "   macro avg       0.53      0.80      0.49      5700\n",
      "weighted avg       0.98      0.75      0.84      5700\n",
      "\n",
      "AUC-ROC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and use KNN\n",
    "knn_model = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5, weights='distance'))\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn_model.predict(X_test) # Threshold does not help enough\n",
    "\n",
    "# Predict probabilities (for AUC-ROC)\n",
    "y_pred_proba = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred_thresholded)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Classification Report (K-Nearest Neighbors):\")\n",
    "print(classification_rep)\n",
    "print(\"AUC-ROC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a16aac-2e85-4100-ac10-8b479a7c98f5",
   "metadata": {},
   "source": [
    "Recall: 86%\n",
    "Precision: 7%\n",
    "\n",
    "### K-nearest neighbors with balanced data and scaled features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9f4e8a01-dbd6-49bd-863f-ca49cad7f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (K-Nearest Neighbors):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92      5579\n",
      "           1       0.08      0.50      0.13       121\n",
      "\n",
      "    accuracy                           0.86      5700\n",
      "   macro avg       0.53      0.69      0.53      5700\n",
      "weighted avg       0.97      0.86      0.91      5700\n",
      "\n",
      "AUC-ROC: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and use KNN\n",
    "knn_model = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5, weights='distance')) # Closer neighbors are given more influence than farther ones\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn_model.predict(X_test_scaled) #\n",
    "\n",
    "# Predict probabilities (for AUC-ROC)\n",
    "y_pred_proba = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Classification Report (K-Nearest Neighbors):\")\n",
    "print(classification_rep)\n",
    "print(\"AUC-ROC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a665f-3c19-4e10-ba1f-6a0af26d33c4",
   "metadata": {},
   "source": [
    "Recall: 50%\n",
    "Precision: 8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364c398-c2d0-4a85-af76-7a3a06e9e4b4",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Models in order based on performance\n",
    "\n",
    "1. Random Forest (R: 87%, P: 9%)\n",
    "2. Random Forest (Balanced & Scaled) (R: 86%, P: 7%)\n",
    "3. K-nearest neighbors (R: 86%, P: 7%)\n",
    "4. Linear SVM (R: 78%, P: 4%)\n",
    "5. Linear SVM (Balanced & Scaled) (R: 55%, P: 4%)\n",
    "7. K-nearest neighbors (Balanced & Scaled) (R: 50%, P: 8%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
